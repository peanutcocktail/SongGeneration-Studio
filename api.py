"""
SongGeneration Studio - Backend API
AI Song Generation with Full Style Control
"""

import os
import sys
import json
import uuid
import asyncio
import re
import argparse
from pathlib import Path
from datetime import datetime
from typing import Optional, List

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# ============================================================================
# GPU/VRAM Detection
# ============================================================================

def get_gpu_info() -> dict:
    """Detect GPU and available VRAM."""
    try:
        import subprocess
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=name,memory.total,memory.free,memory.used', '--format=csv,noheader,nounits'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            gpus = []
            for line in lines:
                parts = [p.strip() for p in line.split(',')]
                if len(parts) >= 4:
                    gpus.append({
                        'name': parts[0],
                        'total_mb': int(parts[1]),
                        'free_mb': int(parts[2]),
                        'used_mb': int(parts[3]),
                        'total_gb': round(int(parts[1]) / 1024, 1),
                        'free_gb': round(int(parts[2]) / 1024, 1),
                    })
            if gpus:
                gpu = gpus[0]  # Primary GPU
                if gpu['free_gb'] >= 24:
                    recommended = 'full'
                else:
                    recommended = 'low'
                return {
                    'available': True,
                    'gpu': gpu,
                    'recommended_mode': recommended,
                    'can_run_full': gpu['free_gb'] >= 24,
                    'can_run_low': gpu['free_gb'] >= 10,
                }
    except Exception as e:
        print(f"[GPU] Detection error: {e}")

    return {
        'available': False,
        'gpu': None,
        'recommended_mode': 'low',
        'can_run_full': False,
        'can_run_low': False,
    }

# Detect GPU on startup
gpu_info = get_gpu_info()
if gpu_info['available']:
    print(f"[GPU] Detected: {gpu_info['gpu']['name']}")
    print(f"[GPU] VRAM: {gpu_info['gpu']['free_gb']}GB free / {gpu_info['gpu']['total_gb']}GB total")
    print(f"[GPU] Recommended mode: {gpu_info['recommended_mode']}")
else:
    print("[GPU] No NVIDIA GPU detected or nvidia-smi not available")

# ============================================================================
# Configuration
# ============================================================================

BASE_DIR = Path(__file__).parent
DEFAULT_MODEL = "songgeneration_base"
OUTPUT_DIR = BASE_DIR / "output"
UPLOADS_DIR = BASE_DIR / "uploads"
STATIC_DIR = BASE_DIR / "web" / "static"

# Create directories
OUTPUT_DIR.mkdir(exist_ok=True)
UPLOADS_DIR.mkdir(exist_ok=True)
(BASE_DIR / "web" / "static").mkdir(parents=True, exist_ok=True)

def get_available_models() -> List[dict]:
    """Detect available model folders in BASE_DIR."""
    models = []
    model_patterns = [
        ("songgeneration_base", "Base (2m30s)", "Chinese + English, 10GB VRAM, max 2m30s"),
        ("songgeneration_base_new", "Base New (2m30s)", "Updated base model, max 2m30s"),
        ("songgeneration_base_full", "Base Full (4m30s)", "Full duration up to 4m30s, 12GB VRAM"),
        ("songgeneration_large", "Large (4m30s)", "Best quality, 22GB VRAM, max 4m30s"),
    ]

    for folder_name, display_name, description in model_patterns:
        folder_path = BASE_DIR / folder_name
        if folder_path.exists():
            # Check for various model file patterns
            has_model = (
                (folder_path / "model.pt").exists() or
                (folder_path / "model.safetensors").exists() or
                any(folder_path.glob("*.pt")) or
                any(folder_path.glob("*.safetensors")) or
                any(folder_path.glob("*.bin")) or
                (folder_path / "config.yaml").exists()  # Some models only have config
            )
            has_config = (folder_path / "config.yaml").exists()

            if has_model or has_config:
                models.append({
                    "id": folder_name,
                    "name": display_name,
                    "description": description,
                    "path": str(folder_path),
                    "has_config": has_config,
                    "status": "ready"
                })

    return models

available_models = get_available_models()
print(f"[CONFIG] Base dir: {BASE_DIR}")
print(f"[CONFIG] Output dir: {OUTPUT_DIR}")
print(f"[CONFIG] Available models: {[m['id'] for m in available_models]}")

# ============================================================================
# Data Models
# ============================================================================

class Section(BaseModel):
    type: str
    lyrics: Optional[str] = None

class SongRequest(BaseModel):
    title: str = "Untitled"
    sections: List[Section]
    gender: str = "female"
    timbre: str = "bright"
    genre: str = "pop"
    emotion: str = "happy"
    instruments: str = "piano and drums"
    bpm: int = 120
    output_mode: str = "mixed"
    auto_prompt_type: Optional[str] = None
    reference_audio_id: Optional[str] = None
    model: str = "songgeneration_base"
    memory_mode: str = "auto"

# ============================================================================
# State
# ============================================================================

generations: dict[str, dict] = {}

def restore_library():
    """Restore completed generations from output directory on startup."""
    global generations
    restored = 0
    
    print(f"[LIBRARY] Scanning output directory: {OUTPUT_DIR}")
    
    if not OUTPUT_DIR.exists():
        return
    
    subdirs = list(OUTPUT_DIR.iterdir())
    for subdir in subdirs:
        if not subdir.is_dir():
            continue
        
        gen_id = subdir.name
        
        # Look for audio files
        audio_files = []
        for search_dir in [subdir, subdir / "audios"]:
            if search_dir.exists():
                audio_files.extend(search_dir.glob("*.flac"))
                audio_files.extend(search_dir.glob("*.wav"))
                audio_files.extend(search_dir.glob("*.mp3"))
        
        if not audio_files:
            continue
        
        audio_files = sorted(set(audio_files))
        
        # Look for metadata file
        metadata_path = subdir / "metadata.json"
        metadata = {}
        if metadata_path.exists():
            try:
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
            except Exception as e:
                print(f"[LIBRARY] Error loading metadata for {gen_id}: {e}")
        
        # Fallback dates
        try:
            file_mtime = datetime.fromtimestamp(audio_files[0].stat().st_mtime).isoformat()
        except:
            file_mtime = datetime.now().isoformat()
            
        generations[gen_id] = {
            "id": gen_id,
            "status": "completed",
            "progress": 100,
            "message": "Complete",
            "title": metadata.get("title", "Untitled"),
            "model": metadata.get("model", "unknown"),
            "created_at": metadata.get("created_at", file_mtime),
            "completed_at": metadata.get("completed_at", file_mtime),
            "output_files": [str(f) for f in audio_files],
            "audio_files": [f.name for f in audio_files],
            "output_dir": str(subdir),
            "metadata": metadata if metadata else {
                "title": "Untitled",
                "model": "unknown",
                "created_at": file_mtime,
            }
        }
        restored += 1
    
    print(f"[LIBRARY] Restored {restored} generation(s)")

# Restore library on import
restore_library()

# ============================================================================
# FastAPI App
# ============================================================================

app = FastAPI(title="SongGeneration Studio", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# Helper Functions
# ============================================================================

def build_lyrics_string(sections: List[Section]) -> str:
    """Build the lyrics string in SongGeneration format."""
    parts = []
    for section in sections:
        tag = f"[{section.type}]"
        if section.lyrics:
            lyrics = section.lyrics.replace('\n', '. ').replace('..', '.').strip()
            if not lyrics.endswith('.'):
                lyrics += '.'
            parts.append(f"{tag} {lyrics}")
        else:
            parts.append(tag)
    return " ; ".join(parts)

def build_description(request: SongRequest) -> str:
    """Build the description string for style control."""
    parts = []

    if request.gender and request.gender != "auto":
        parts.append(request.gender)

    if request.timbre:
        parts.append(request.timbre)

    if request.genre and request.genre != "Auto":
        parts.append(request.genre)

    if request.emotion:
        parts.append(request.emotion)

    if request.instruments:
        parts.append(request.instruments)

    if request.bpm:
        parts.append(f"the bpm is {request.bpm}")

    return ", ".join(parts) + "." if parts else ""

async def run_generation(gen_id: str, request: SongRequest, reference_path: Optional[str]):
    """Run the actual SongGeneration inference."""
    global generations

    try:
        print(f"[GEN {gen_id}] Starting generation...")
        generations[gen_id]["status"] = "processing"
        generations[gen_id]["message"] = "Preparing input..."
        generations[gen_id]["progress"] = 5

        # Validate model
        model_id = request.model or DEFAULT_MODEL
        model_path = BASE_DIR / model_id

        if not model_path.exists():
            raise Exception(f"Model not found: {model_id}")

        print(f"[GEN {gen_id}] Using model: {model_id}")
        generations[gen_id]["model"] = model_id

        # Create input JSONL
        input_file = UPLOADS_DIR / f"{gen_id}_input.jsonl"
        output_subdir = OUTPUT_DIR / gen_id
        output_subdir.mkdir(exist_ok=True)

        lyrics = build_lyrics_string(request.sections)

        input_data = {
            "idx": gen_id,
            "gt_lyric": lyrics,
        }

        description = ""

        if reference_path:
            input_data["prompt_audio_path"] = reference_path
            print(f"[GEN {gen_id}] Using reference audio (no descriptions to avoid conflicts)")
        else:
            description = build_description(request)
            if description:
                input_data["descriptions"] = description

            genre_map = {
                "pop": "Pop", "r&b": "R&B", "rnb": "R&B",
                "dance": "Dance", "electronic": "Dance", "edm": "Dance",
                "jazz": "Jazz", "folk": "Folk", "acoustic": "Folk",
                "rock": "Rock", "metal": "Metal", "heavy metal": "Metal",
                "reggae": "Reggae", "chinese": "Chinese Style",
            }

            genre_lower = request.genre.lower() if request.genre else ""
            auto_type = genre_map.get(genre_lower, "Auto")
            input_data["auto_prompt_audio_type"] = auto_type

        print(f"[GEN {gen_id}] Lyrics: {lyrics[:200]}...")
        print(f"[GEN {gen_id}] Description: {description if description else '(using reference audio)'}")
        print(f"[GEN {gen_id}] Input data: {json.dumps(input_data, indent=2)}")

        with open(input_file, 'w', encoding='utf-8') as f:
            json.dump(input_data, f, ensure_ascii=False)
            f.write('\n')

        generations[gen_id]["message"] = f"Loading model ({model_id})..."
        generations[gen_id]["progress"] = 10

        # Build command
        cmd = [
            sys.executable, "generate.py",
            "--ckpt_path", model_id,
            "--input_jsonl", str(input_file),
            "--save_dir", str(output_subdir),
        ]

        # Memory mode handling
        memory_mode = request.memory_mode
        if memory_mode == "auto":
            current_gpu = get_gpu_info()
            if current_gpu['available'] and current_gpu['can_run_full']:
                memory_mode = "full"
                print(f"[GEN {gen_id}] Auto-selected FULL mode ({current_gpu['gpu']['free_gb']}GB free)")
            else:
                memory_mode = "low"
                free_gb = current_gpu['gpu']['free_gb'] if current_gpu['available'] else 'unknown'
                print(f"[GEN {gen_id}] Auto-selected LOW memory mode ({free_gb}GB free)")

        generations[gen_id]["memory_mode"] = memory_mode
        print(f"[GEN {gen_id}] Memory mode: {memory_mode}")

        # Output mode flags
        if request.output_mode == "vocal":
            cmd.append("--vocal")
        elif request.output_mode == "bgm":
            cmd.append("--bgm")
        elif request.output_mode == "separate":
            cmd.append("--separate")

        print(f"[GEN {gen_id}] Command: {' '.join(cmd)}")

        generations[gen_id]["message"] = "Starting inference..."
        generations[gen_id]["progress"] = 15

        # Set up environment with correct PYTHONPATH
        flow_vae_dir = BASE_DIR / "codeclm" / "tokenizer" / "Flow1dVAE"
        env = os.environ.copy()
        env["PYTHONPATH"] = f"{BASE_DIR};{flow_vae_dir};{env.get('PYTHONPATH', '')}"
        env["PYTHONUTF8"] = "1"

        process = await asyncio.create_subprocess_exec(
            *cmd,
            cwd=str(BASE_DIR),
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            env=env,
            limit=1024*1024
        )

        generations[gen_id]["message"] = "Generating song (this takes several minutes)..."
        generations[gen_id]["progress"] = 20

        all_stderr = []
        while True:
            try:
                line = await process.stderr.readline()
                if not line:
                    break
                line_str = line.decode('utf-8', errors='ignore').strip()
                if line_str:
                    log_line = line_str[:200] + '...' if len(line_str) > 200 else line_str
                    all_stderr.append(log_line)
                    print(f"[GEN {gen_id}] {log_line}")

                    if "%" in line_str:
                        match = re.search(r'(\d+)%', line_str)
                        if match:
                            pct = int(match.group(1))
                            progress = min(95, 20 + (pct * 0.75))
                            generations[gen_id]["progress"] = progress
                            generations[gen_id]["message"] = f"Generating... {pct}%"
            except ValueError:
                chunk = await process.stderr.read(8192)
                if not chunk:
                    break
                chunk_str = chunk.decode('utf-8', errors='ignore')
                if "%" in chunk_str:
                    match = re.search(r'(\d+)%', chunk_str)
                    if match:
                        pct = int(match.group(1))
                        progress = min(95, 20 + (pct * 0.75))
                        generations[gen_id]["progress"] = progress
                        generations[gen_id]["message"] = f"Generating... {pct}%"

        await process.wait()
        stdout = await process.stdout.read()

        print(f"[GEN {gen_id}] Process finished with code {process.returncode}")

        if process.returncode != 0:
            stderr_text = '\n'.join(all_stderr[-20:])
            raise Exception(f"Generation failed (code {process.returncode}): {stderr_text}")

        # Find output files
        audios_dir = output_subdir / "audios"
        output_files = []

        for search_dir in [audios_dir, output_subdir]:
            if search_dir.exists():
                output_files.extend(search_dir.glob("*.wav"))
                output_files.extend(search_dir.glob("*.flac"))
                output_files.extend(search_dir.glob("*.mp3"))

        output_files = sorted(set(output_files))
        print(f"[GEN {gen_id}] Found {len(output_files)} audio files: {[f.name for f in output_files]}")

        if not output_files:
            print(f"[GEN {gen_id}] Contents of {output_subdir}:")
            for item in output_subdir.rglob("*"):
                print(f"[GEN {gen_id}]   - {item.relative_to(output_subdir)}")
            raise Exception("No output file generated")

        generations[gen_id]["status"] = "completed"
        generations[gen_id]["progress"] = 100
        generations[gen_id]["message"] = "Song generated successfully!"
        generations[gen_id]["output_files"] = [str(f) for f in output_files]
        generations[gen_id]["output_file"] = str(output_files[0])
        generations[gen_id]["completed_at"] = datetime.now().isoformat()

        # Save complete metadata for library restoration
        try:
            metadata_path = output_subdir / "metadata.json"
            metadata = {
                "id": gen_id,
                "title": request.title,
                "model": model_id,
                "created_at": generations[gen_id].get("created_at", datetime.now().isoformat()),
                "completed_at": datetime.now().isoformat(),
                "gender": request.gender,
                "timbre": request.timbre,
                "genre": request.genre,
                "emotion": request.emotion,
                "instruments": request.instruments,
                "bpm": request.bpm,
                "output_mode": request.output_mode,
                "memory_mode": request.memory_mode,
                "sections": [{"type": s.type, "lyrics": s.lyrics} for s in request.sections],
                "description": description,
                "reference_audio": reference_path if reference_path else None,
                "audio_files": [f.name for f in output_files],
            }
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            generations[gen_id]["metadata"] = metadata
            
        except Exception as meta_err:
            print(f"[GEN {gen_id}] Warning: Could not save metadata: {meta_err}")

        input_file.unlink(missing_ok=True)

    except Exception as e:
        print(f"[GEN {gen_id}] ERROR: {e}")
        import traceback
        traceback.print_exc()
        generations[gen_id]["status"] = "failed"
        generations[gen_id]["message"] = str(e)

# ============================================================================
# API Routes
# ============================================================================

@app.get("/")
async def root():
    """Serve the main UI."""
    index_path = STATIC_DIR / "index.html"
    if index_path.exists():
        response = FileResponse(index_path)
        response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
        response.headers["Pragma"] = "no-cache"
        response.headers["Expires"] = "0"
        return response
    return {"message": "SongGeneration Studio API", "status": "running"}

@app.get("/api/health")
async def health_check():
    """Health check endpoint."""
    global available_models, gpu_info
    available_models = get_available_models()
    gpu_info = get_gpu_info()
    return {
        "status": "ok",
        "models": available_models,
        "default_model": DEFAULT_MODEL,
        "gpu": gpu_info
    }

@app.get("/api/gpu")
async def get_gpu_status():
    """Get current GPU status and VRAM."""
    global gpu_info
    gpu_info = get_gpu_info()
    return gpu_info

@app.get("/api/models")
async def list_models():
    """List all available models."""
    global available_models
    available_models = get_available_models()
    return {
        "models": available_models,
        "default": DEFAULT_MODEL
    }

@app.post("/api/upload-reference")
async def upload_reference(file: UploadFile = File(...)):
    """Upload a reference audio file."""
    allowed_ext = ('.wav', '.mp3', '.flac', '.ogg')
    if not file.filename.lower().endswith(allowed_ext):
        raise HTTPException(400, f"Invalid file type. Allowed: {allowed_ext}")

    file_id = str(uuid.uuid4())
    file_path = UPLOADS_DIR / f"{file_id}_{file.filename}"

    content = await file.read()
    with open(file_path, 'wb') as f:
        f.write(content)

    print(f"[UPLOAD] Saved reference: {file_path} ({len(content)} bytes)")

    return {
        "id": file_id,
        "filename": file.filename,
        "path": str(file_path)
    }

@app.post("/api/generate")
async def generate_song(request: SongRequest, background_tasks: BackgroundTasks):
    """Start a new song generation."""
    gen_id = str(uuid.uuid4())[:8]

    print(f"[API] New generation request: {gen_id}")
    print(f"[API] Title: {request.title}")
    print(f"[API] Model: {request.model}")
    print(f"[API] Sections: {len(request.sections)}")
    print(f"[API] Style: {request.genre}, {request.emotion}, {request.gender}")

    reference_path = None
    if request.reference_audio_id:
        ref_files = list(UPLOADS_DIR.glob(f"{request.reference_audio_id}_*"))
        if ref_files:
            reference_path = str(ref_files[0])

    generations[gen_id] = {
        "id": gen_id,
        "title": request.title,
        "model": request.model,
        "status": "pending",
        "progress": 0,
        "message": "Queued for generation...",
        "output_file": None,
        "output_files": [],
        "created_at": datetime.now().isoformat(),
        "completed_at": None
    }

    background_tasks.add_task(run_generation, gen_id, request, reference_path)

    return {"generation_id": gen_id}

@app.get("/api/generation/{gen_id}")
async def get_generation_status(gen_id: str):
    """Get the status of a generation."""
    if gen_id not in generations:
        raise HTTPException(404, "Generation not found")
    return generations[gen_id]

@app.get("/api/audio/{gen_id}/{track_idx}")
async def get_audio_track(gen_id: str, track_idx: int):
    """Stream a specific track from a generation."""
    if gen_id not in generations:
        raise HTTPException(404, "Generation not found")

    gen = generations[gen_id]
    if gen["status"] != "completed":
        raise HTTPException(400, "Generation not complete")

    output_files = gen.get("output_files", [])
    if track_idx >= len(output_files):
        raise HTTPException(404, f"Track {track_idx} not found")

    output_path = Path(output_files[track_idx])
    if not output_path.exists():
        raise HTTPException(404, "Audio file not found")

    ext = output_path.suffix.lower()
    media_types = {".wav": "audio/wav", ".flac": "audio/flac", ".mp3": "audio/mpeg"}

    return FileResponse(
        output_path,
        media_type=media_types.get(ext, "audio/wav"),
        filename=f"{gen.get('title', gen_id)}_track{track_idx + 1}{ext}"
    )

@app.get("/api/generations")
async def list_generations():
    """List all generations."""
    return list(generations.values())

@app.get("/api/presets")
async def get_presets():
    """Get available style presets."""
    return {
        "genres": ["Pop", "Rock", "Metal", "Jazz", "R&B", "Folk", "Dance", "Reggae", "Chinese Style", "Electronic"],
        "emotions": ["happy", "sad", "energetic", "romantic", "angry", "peaceful", "melancholic", "hopeful"],
        "timbres": ["bright", "dark", "soft", "powerful", "warm", "clear", "raspy", "smooth"],
        "genders": ["female", "male"],
        "auto_prompts": ["Auto", "Pop", "Rock", "Metal", "Jazz", "Folk", "Dance", "R&B", "Reggae"]
    }

# Serve static files
if STATIC_DIR.exists():
    app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")

# ============================================================================
# Main
# ============================================================================

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="SongGeneration Studio API Server")
    parser.add_argument("--host", default="127.0.0.1", help="Host to bind to")
    parser.add_argument("--port", type=int, default=8000, help="Port to bind to")
    args = parser.parse_args()

    print()
    print("=" * 60)
    print("  SongGeneration Studio")
    print(f"  Open http://{args.host}:{args.port} in your browser")
    print("=" * 60)
    print()

    uvicorn.run(app, host=args.host, port=args.port)
